{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: keras_facenet in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: mtcnn in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (from keras_facenet) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: lz4>=4.3.3 in c:\\users\\kisho\\desktop\\cyfuture\\.venv\\lib\\site-packages (from mtcnn->keras_facenet) (4.4.3)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python opencv-contrib-python argparse keras_facenet scipy scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_facenet import FaceNet\n",
    "embedder = FaceNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection\n",
    "    - Faces Detection\n",
    "    - Vector encodings of each face\n",
    "    - labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,numpy as np\n",
    "\n",
    "def CollectData(DIR,embedder=embedder):\n",
    "    people = [name for name in os.listdir(DIR) if os.path.isdir(os.path.join(DIR,name))]\n",
    "\n",
    "    features = [] # to store vector embedding of each face\n",
    "    labels = [] # person's index in people array of each face detected\n",
    "\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\"} \n",
    "\n",
    "    for person in people :\n",
    "        \n",
    "        path = os.path.join(DIR,person)\n",
    "        label = people.index(person)\n",
    "        count = 0\n",
    "        for img in os.listdir(path) :\n",
    "            if not any(img.lower().endswith(ext) for ext in image_extensions): # running code only for image files\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(path,img)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (800, 600))\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            detections = embedder.extract(img, threshold=0.95) # Every image should contain faces of only one person\n",
    "            \n",
    "            for detection in detections:\n",
    "                features.append(detection['embedding'])\n",
    "                labels.append(label)\n",
    "                count += 1\n",
    "            if count == 5 :\n",
    "                break\n",
    "            \n",
    "            \n",
    "    features = np.array(features,dtype=object)\n",
    "    labels = np.array(labels)\n",
    "    np.save('Memory/labels.npy',labels)\n",
    "    np.save('Memory/features.npy',features)\n",
    "    return features,labels,people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing and Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def PreprocessAndLearn(features,labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    print(\"Dataset: train=%d, test=%d\" % (np.shape(X_train)[0],(np.shape(X_test))[0])) \n",
    "    # normalize input vectors\n",
    "    in_encoder = Normalizer()\n",
    "    TrainX_norm = in_encoder.transform(X_train)\n",
    "    TestX_norm = in_encoder.transform(X_test)\n",
    "    # fit model\n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(TrainX_norm, y_train)\n",
    "    # predict\n",
    "    yhat_train = model.predict(TrainX_norm)\n",
    "    yhat_test = model.predict(TestX_norm)\n",
    "    # score\n",
    "    score_train = accuracy_score(y_train, yhat_train)\n",
    "    score_test = accuracy_score(y_test, yhat_test)\n",
    "    # summarize\n",
    "    print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
    "    return model, score_train,score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "(25, 512) (25,)\n",
      "Dataset: train=20, test=5\n",
      "Accuracy: train=100.000, test=100.000\n"
     ]
    }
   ],
   "source": [
    "training_data='Faces/Sports_Persons'\n",
    "features,labels,people = CollectData(training_data)\n",
    "print(np.shape(features),np.shape(labels))\n",
    "model,score_test,score_train=PreprocessAndLearn(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Memory/Models/Sports Celebraties_trained_model.pkl']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "trained_on = \"Sports Celebraties\"\n",
    "metadata = {\n",
    "    \"model\": model,\n",
    "    \"description\": f\"SVC model trained on {trained_on} classification\",\n",
    "    \"target_names\": people,\n",
    "    \"Accuracy of the model(train,test)\":(score_train,score_test),\n",
    "}\n",
    "joblib.dump(metadata,f'Memory/Models/{trained_on}_trained_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,joblib\n",
    "def predict_faces(img_path,model=None,people=None,trained_model=None):\n",
    "    test_image = img_path\n",
    "    if trained_model is not None :\n",
    "        model_data = joblib.load(trained_model)\n",
    "        people = model_data['target_names']\n",
    "        model = model_data['model']\n",
    "        print(model_data)\n",
    "    in_encoder = Normalizer()\n",
    "    print(\"Face Recognition among :\",people)\n",
    "\n",
    "    img = cv2.imread(test_image)\n",
    "    if img is None:\n",
    "        print('img not found')\n",
    "        return\n",
    "    img = cv2.resize(img, (800, 600))\n",
    "    # cv2.imshow(\"test image\",img)\n",
    "\n",
    "    detections = embedder.extract(img, threshold=0.95)      # Face Detection\n",
    "    if detections == [] :\n",
    "        print(\"No Faces Detected\")\n",
    "        return\n",
    "    embeddings = [each['embedding'] for each in detections] # Embedding collection\n",
    "    TestX_norm = in_encoder.transform(embeddings)           # Normalizing  embedding\n",
    "    labels = model.predict(TestX_norm)                      #Face recognition\n",
    "    for i,detection in enumerate(detections):\n",
    "        (x,y,w,h) = detection['box']\n",
    "        label= labels[i]\n",
    "        print(people[label])\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),thickness=2)\n",
    "        cv2.putText(img,f\"{people[label]}\",(x-10,y-10),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,0),thickness=2)\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"Detected faces\",img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Recognition among : ['lionel_messi', 'maria_sharapova', 'roger_federer', 'serena_williams', 'virat_kohli']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "lionel_messi\n",
      "virat_kohli\n",
      "roger_federer\n"
     ]
    }
   ],
   "source": [
    "# Test on above learned model (5 sports persons) : https://www.kaggle.com/datasets/vparh7/sports-celebrity-images\n",
    "image_path = 'face_rec.png'   # Path to the image that needs to be predicted\n",
    "predict_faces(image_path,model,people)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': SVC(kernel='linear', probability=True), 'description': 'SVC model trained on Indian_Celebraties classification', 'target_names': ['Aamir_Khan', 'Abhay_Deol', 'Abhishek_Bachchan', 'Aftab_Shivdasani', 'Aishwarya_Rai', 'Ajay_Devgn', 'Akshaye_Khanna', 'Akshay_Kumar', 'Alia_Bhatt', 'Ameesha_Patel', 'Amitabh_Bachchan', 'Amrita_Rao', 'Amy_Jackson', 'Anil_Kapoor', 'Anushka_Sharma', 'Anushka_Shetty', 'Arjun_Kapoor', 'Arjun_Rampal', 'Arshad_Warsi', 'Asin', 'Ayushmann_Khurrana', 'Bhumi_Pednekar', 'Bipasha_Basu', 'Bobby_Deol', 'Deepika_Padukone', 'Disha_Patani', 'Emraan_Hashmi', 'Esha_Gupta', 'Farhan_Akhtar', 'Govinda', 'Hrithik_Roshan', 'Huma_Qureshi', 'Ileana', 'Irrfan_Khan', 'Jacqueline_Fernandez', 'John_Abraham', 'Juhi_Chawla', 'Kajal_Aggarwal', 'Kajol', 'Kangana_Ranaut', 'Kareena_Kapoor', 'Karisma_Kapoor', 'Kartik_Aaryan', 'Katrina_Kaif', 'Kiara_Advani', 'Kriti_Kharbanda', 'Kriti_Sanon', 'Kunal_Khemu', 'Lara_Dutta', 'Madhuri_Dixit', 'Manoj_Bajpayee', 'Mrunal_Thakur', 'Nana_Patekar', 'Nargis_Fakhri', 'Naseeruddin_Shah', 'Nushrat_Bharucha', 'Paresh_Rawal', 'Parineeti_Chopra', 'Pooja_Hegde', 'Prabhas', 'Prachi_Desai', 'Preity_Zinta', 'Priyanka_Chopra', 'Rajkummar_Rao', 'Ranbir_Kapoor', 'Randeep_Hooda', 'Rani_Mukerji', 'Ranveer_Singh', 'Richa_Chadda', 'Riteish_Deshmukh', 'R_Madhavan', 'Saif_Ali_Khan', 'Salman_Khan', 'Sanjay_Dutt', 'Sara_Ali_Khan', 'Shahid_Kapoor', 'Shah_Rukh_Khan', 'Shilpa_Shetty', 'Shraddha_Kapoor', 'Shreyas_Talpade', 'Shruti_Haasan', 'Sidharth_Malhotra', 'Sonakshi_Sinha', 'Sonam_Kapoor', 'Suniel_Shetty', 'Sunny_Deol', 'Sushant_Singh_Rajput', 'Taapsee_Pannu', 'Tabu', 'Tamannaah_Bhatia', 'Tiger_Shroff', 'Tusshar_Kapoor', 'Uday_Chopra', 'Vaani_Kapoor', 'Varun_Dhawan', 'Vicky_Kaushal', 'Vidya_Balan', 'Vivek_Oberoi', 'Yami_Gautam', 'Zareen_Khan'], 'Accuracy of the model(train,test)': (0.7, 0.9748743718592965)}\n",
      "Face Recognition among : ['Aamir_Khan', 'Abhay_Deol', 'Abhishek_Bachchan', 'Aftab_Shivdasani', 'Aishwarya_Rai', 'Ajay_Devgn', 'Akshaye_Khanna', 'Akshay_Kumar', 'Alia_Bhatt', 'Ameesha_Patel', 'Amitabh_Bachchan', 'Amrita_Rao', 'Amy_Jackson', 'Anil_Kapoor', 'Anushka_Sharma', 'Anushka_Shetty', 'Arjun_Kapoor', 'Arjun_Rampal', 'Arshad_Warsi', 'Asin', 'Ayushmann_Khurrana', 'Bhumi_Pednekar', 'Bipasha_Basu', 'Bobby_Deol', 'Deepika_Padukone', 'Disha_Patani', 'Emraan_Hashmi', 'Esha_Gupta', 'Farhan_Akhtar', 'Govinda', 'Hrithik_Roshan', 'Huma_Qureshi', 'Ileana', 'Irrfan_Khan', 'Jacqueline_Fernandez', 'John_Abraham', 'Juhi_Chawla', 'Kajal_Aggarwal', 'Kajol', 'Kangana_Ranaut', 'Kareena_Kapoor', 'Karisma_Kapoor', 'Kartik_Aaryan', 'Katrina_Kaif', 'Kiara_Advani', 'Kriti_Kharbanda', 'Kriti_Sanon', 'Kunal_Khemu', 'Lara_Dutta', 'Madhuri_Dixit', 'Manoj_Bajpayee', 'Mrunal_Thakur', 'Nana_Patekar', 'Nargis_Fakhri', 'Naseeruddin_Shah', 'Nushrat_Bharucha', 'Paresh_Rawal', 'Parineeti_Chopra', 'Pooja_Hegde', 'Prabhas', 'Prachi_Desai', 'Preity_Zinta', 'Priyanka_Chopra', 'Rajkummar_Rao', 'Ranbir_Kapoor', 'Randeep_Hooda', 'Rani_Mukerji', 'Ranveer_Singh', 'Richa_Chadda', 'Riteish_Deshmukh', 'R_Madhavan', 'Saif_Ali_Khan', 'Salman_Khan', 'Sanjay_Dutt', 'Sara_Ali_Khan', 'Shahid_Kapoor', 'Shah_Rukh_Khan', 'Shilpa_Shetty', 'Shraddha_Kapoor', 'Shreyas_Talpade', 'Shruti_Haasan', 'Sidharth_Malhotra', 'Sonakshi_Sinha', 'Sonam_Kapoor', 'Suniel_Shetty', 'Sunny_Deol', 'Sushant_Singh_Rajput', 'Taapsee_Pannu', 'Tabu', 'Tamannaah_Bhatia', 'Tiger_Shroff', 'Tusshar_Kapoor', 'Uday_Chopra', 'Vaani_Kapoor', 'Varun_Dhawan', 'Vicky_Kaushal', 'Vidya_Balan', 'Vivek_Oberoi', 'Yami_Gautam', 'Zareen_Khan']\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "Disha_Patani\n",
      "Tiger_Shroff\n"
     ]
    }
   ],
   "source": [
    "# To test on Pre Trained Top 100 indian Celebraties Data Set :  https://www.kaggle.com/datasets/sarthak1203/indian-celebrities?resource=download\n",
    "image_path = 'image.png' \n",
    "model_path = f'Memory/Models/Indian_Celebraties_trained_model.pkl'\n",
    "predict_faces(image_path,trained_model=model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
